# ğŸ§© LLM Tokenizer with Pricing Calculator in Zig

This project is a **Byte Pair Encoding (BPE) tokenizer** written in [Zig](https://ziglang.org) that tokenizes text and calculates the cost across various LLM providers.  
It reads input from `src/prompt.txt`, performs BPE tokenization, and displays a comprehensive pricing table for popular language models.

---

## âœ¨ Features

- Pure Zig 0.15 implementation (no dependencies outside `std`)
- **BPE Tokenization**:
  - Iteratively finds and merges most frequent adjacent byte pairs
  - Stops when no pair occurs more than once
  - ANSI-colored output for token visualization
- **LLM Pricing Calculator**:
  - Calculates prompt costs for 18+ popular models
  - Models grouped by price tier (budget to ultra-premium)
  - Displays cost per prompt and price per million tokens
- Reads input from `src/prompt.txt` file

---

## ğŸ” Example

Create a file `src/prompt.txt` with your text:

```
Hello world! This is a test prompt.
```

Run:

```bash
zig build run
```

Output:
- Colorized tokens (ANSI colors)
- Total token count
- Pricing table showing costs across different LLM providers

Example pricing table output:
```
Total Tokens: 20

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ Model                        â”‚ Prompt Cost       â”‚ Price per Million    â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Amazon Nova Micro            â”‚ $    0.0000007000 â”‚ $               0.04 â•‘
â•‘ GPT-4o Mini                  â”‚ $      0.00000300 â”‚ $               0.15 â•‘
â•‘ Claude 3.5 Sonnet            â”‚ $      0.00006000 â”‚ $               3.00 â•‘
â•‘ o1 Pro                       â”‚ $      0.00300000 â”‚ $             150.00 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## âš¡ Usage

1. **Add your text** to `src/prompt.txt`
2. **Build and run**:
   ```bash
   zig build run
   ```

### Adding New Models

To add new LLM models, edit the `models` array in `src/main.zig`:

```zig
const models = [_]Model{
    .{ .name = "Your Model Name", .price_per_million = 0.50 },
    // ... other models
};
```

---

## ğŸ“‹ Supported Models

The tokenizer includes pricing for:
- **Budget**: Amazon Nova, Gemini Flash, GPT-4o Mini, Claude Haiku
- **Mid-range**: Claude 3.5 Haiku, o1-mini, Gemini Pro
- **Premium**: GPT-4o, Claude 3.5 Sonnet, Grok 3
- **Enterprise**: Claude Opus, o1
- **Ultra-premium**: o3 Pro, GPT-4.5, o1 Pro

---

## ğŸš€ Next Steps

* [x] Allow reading text from a file instead of hardcoding
* [ ] Support for different tokenization algorithms
* [ ] Export results to JSON/CSV
* [ ] Command-line arguments for file input

